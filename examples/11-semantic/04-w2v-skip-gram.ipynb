{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**извлечение признаков из текста на естественном языке**\n",
    "\n",
    "word2vec : skip-gram\n",
    "\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gzip\n",
    "import numpy as np\n",
    "from numpy import random as rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем текст "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "символов:601090\n",
      "\n",
      "Вы прилетели в Нью-Йорк и остановились в одном из отелей, глядящих окнами на Центральный парк. Наутро по приезде вы вышли из отеля, вдохнули полной грудью очищенный зеленью парка воздух и, взглянув на часы, - пора было начинать хлопотливый день, - направились к первому из таксомоторов, выстроившихся вереницей у подъезда.\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('../data/text/lobas-taxisty.txt.gz','rt') as f: \n",
    "    text = f.read()[654:]  # ...и выкидываем заголовок\n",
    "print('символов:%i\\n'%(len(text)))\n",
    "print(text[:327].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## выполняем токенизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk version: 3.6.7\n"
     ]
    }
   ],
   "source": [
    "from nltk import __version__ as nltk_version\n",
    "print('nltk version:',nltk_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "предложений: 6627\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['полисменом'],\n",
       " ['спросил',\n",
       "  'шмуэля',\n",
       "  'приглашая',\n",
       "  'его',\n",
       "  'сторонку',\n",
       "  'чтобы',\n",
       "  'нашему',\n",
       "  'разговору',\n",
       "  'не',\n",
       "  'помешали',\n",
       "  'трепачи-кэбби'],\n",
       " ['пять', 'минут', 'десять', 'такси', 'все', 'мчатся', 'мчатся', 'мимо'],\n",
       " ['слушай', 'ты', 'меня', 'не', 'один'],\n",
       " ['он', 'рентует', 'сказал', 'ежик']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "from nltk.tokenize import sent_tokenize as nltk_sentence_split\n",
    "from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "stopwords = set() # set(nltk_stopwords.words('russian')) \n",
    "\n",
    "text = [ \n",
    "    [ \n",
    "     t.lower() \n",
    "     for t in nltk_tokenize_word(s) \n",
    "     if re.match(r'[а-я -]+',t.lower()) and len(t)>1 \n",
    "#      if not( (t.lower() in stopwords) or (len(t)<3) ) \n",
    "    ] # разбиваем предложения на слова\n",
    "    for s in nltk_sentence_split(text) # режем текст на отдельные предложения\n",
    "]\n",
    "\n",
    "print('предложений: %i\\n'%(len(text)))\n",
    "\n",
    "sample(text,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменяем слова в тексте их номерами в словаре\n",
    "words = sorted(set(sum(text,[]))) # словарь из текста\n",
    "vocab =  { w:i for i,w in enumerate(words) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер словаря: 22195 слов\n"
     ]
    }
   ],
   "source": [
    "n_words = len(vocab) # количество слов в словаре\n",
    "print( \"размер словаря: %i слов\" % n_words )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## собираем контексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество n-gram: 54447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('кожей', 'опасной', 'для', 'кэбби', 'поездки'),\n",
       " ('по', 'второму', 'возьмись', 'обеими', 'руками'),\n",
       " ('перекрестке', 'мы', 'остались', 'полицейским', 'вдвоем'),\n",
       " ('ответе', 'он', 'не', 'употребил', 'ни'),\n",
       " ('то', 'рекламных', 'роликах', 'который', 'тех')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.util import bigrams\n",
    "from nltk.util import ngrams as nltk_ngrams\n",
    "\n",
    "# вынимаем все n-gram из текста\n",
    "ngram_len = 5\n",
    "\n",
    "text_ngrams = [ \n",
    "    ngram \n",
    "    for s in text if len(s)>ngram_len\n",
    "    for ngram in nltk_ngrams(s,ngram_len) \n",
    "]\n",
    "print('количество n-gram: %i'%(len(set(text_ngrams))))\n",
    "sample(text_ngrams,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ngrams = sample(text_ngrams,1_000) # сокращаем учебный набор для ускорения процесса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### кодируем слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (1000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.array([ [ vocab[w] for w in ngrams ] for ngrams in text_ngrams ]) # кодируем слова\n",
    "\n",
    "wn = ngram_len//2\n",
    "\n",
    "W = T[:,wn] # коды слов\n",
    "C = np.delete(T,wn,axis=1) # коды слов контекста\n",
    "\n",
    "assert len(C) == len(W)\n",
    "\n",
    "C.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del text_ngrams\n",
    "del text\n",
    "del T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4, 22195), (1000, 22195))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # унитарное кодирование слов (one-hot-encoding)\n",
    "E = np.eye(n_words,dtype=np.int8)\n",
    "\n",
    "Wbin = np.vstack([ E[c] for c in W ])\n",
    "Cbin = np.vstack([ np.vstack([ E[c] for c in Ci ])[np.newaxis,:] for Ci in C ]) \n",
    "\n",
    "Cbin.shape, Wbin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del W\n",
    "del C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим модель Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем по контексту предсказывать слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ф-ция активации скрытого слоя - линейная\n",
    "# def act(s): return s\n",
    "\n",
    "# ф-ция активации выходного слоя\n",
    "def softmax(s): \n",
    "    e = np.exp(s)\n",
    "    return e/e.sum(axis=1).reshape(s.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_step(W,Vi,Vo):\n",
    "    H = W.dot(Vi) # значения скрытого слоя\n",
    "    U = H.dot(Vo) # состояния выходного слоя\n",
    "    O = softmax(U) # выход сети\n",
    "    return H,U,O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потери\n",
    "\n",
    "$$E = \\left| \\sum\\limits_i\\log\\left( \\sum\\limits_k \\exp(U_{ik}) \\right) - \\sum\\limits_i\\sum\\limits_k\\sum\\limits_j (U_{ik} * Q_{ijk}) \\right| $$\n",
    "\n",
    "\n",
    "$U_{ik}$ состояние k-того нейрона выходного слоя для слова $i$     \n",
    "$Q_{ij}$ слово $j$ контекста слова $i$   \n",
    "где ∗ - операция поэлементного умножения векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_loss(U,C):\n",
    "    n,cws,v = C.shape \n",
    "    # количество примеров\n",
    "    # размер окна контекста   \n",
    "    # количество слов в словаре\n",
    "\n",
    "    Us = np.log( np.exp(U).sum(axis=1) ).sum()\n",
    "\n",
    "    Uo = 0.0\n",
    "    for i in range(cws): # для всех слов контекста\n",
    "        Ci = C[:,i,:].reshape([n,v]) # набор слов контекста i\n",
    "        Uo += (U*Ci).sum() # значения выходного слоя для слов x контекста i\n",
    "\n",
    "    return np.abs(Us-Uo)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_grad(C,W,H,O,Vo):\n",
    "    n,cws,v = C.shape\n",
    "        # количество примеров\n",
    "        # размер окна контекста   \n",
    "        # количество слов в словаре\n",
    "\n",
    "    gVi = gVo = 0.0 \n",
    "\n",
    "    for i in range(cws):\n",
    "        Ci = C[:,i,:].reshape([n,v]) # слово i контекста\n",
    "        D = O - Ci # ошибка на слове контекста i\n",
    "        gVo += D.T.dot(H).T\n",
    "        gVi += W.T.dot(D).dot(Vo.T)\n",
    "\n",
    "    return gVi,gVo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_weigth_norm(v,w):\n",
    "    nn = np.linalg.norm( np.hstack([ v.flatten(), w.flatten() ]) )\n",
    "    #nn = np.abs( np.hstack([ v.flatten(), w.flatten() ]) ).max()\n",
    "    return (v/nn,w/nn) if nn!=0.0 else (v,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Wbin.shape[1] # количество слов в словаре\n",
    "k = 30 # размер скрытого слоя H\n",
    "\n",
    "Vi = rng.normal(scale=.01,size=(n,k))\n",
    "Vo = rng.normal(scale=.01,size=(k,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10.007608172486618\n",
      "2 10.003057910201477\n",
      "3 9.994591355837711\n",
      "4 9.979137914476407\n",
      "5 9.954991928803315\n",
      "6 9.921173659905861\n",
      "7 9.877113710278605\n",
      "8 9.822454168474657\n",
      "9 9.75695705126269\n",
      "10 9.680465467676257\n",
      "11 9.592903883462656\n",
      "12 9.494354634505987\n",
      "13 9.385383584183709\n",
      "14 9.268018691458188\n",
      "15 9.148588774357972\n",
      "16 9.032865907036221\n",
      "17 8.912279443581356\n",
      "18 8.790837364620847\n",
      "19 8.662486816683831\n",
      "20 8.531249505256403\n",
      "21 8.394591550540333\n",
      "22 8.25485777356277\n",
      "23 8.110755746287388\n",
      "24 7.963520008517788\n",
      "25 7.812428541030236\n",
      "26 7.658189512944098\n",
      "27 7.500839713327542\n",
      "28 7.341058683010376\n",
      "29 7.178955031246639\n",
      "30 7.014658917330326\n",
      "31 6.848205608345062\n",
      "32 6.67987905606326\n",
      "33 6.510042332434998\n",
      "34 6.339116560253408\n",
      "35 6.167483772395991\n",
      "36 5.995487606590595\n",
      "37 5.823382654103596\n",
      "38 5.6513093224495\n",
      "39 5.479310723117533\n",
      "40 5.307404072732535\n",
      "41 5.135648770699531\n",
      "42 4.964184173139797\n",
      "43 4.793222300066258\n",
      "44 4.6230066647159695\n",
      "45 4.453753002737789\n",
      "46 4.285594042861668\n",
      "47 4.118546615759442\n",
      "48 3.9525071946642383\n",
      "49 3.7872728347591047\n",
      "50 3.6225825668089757\n",
      "51 3.4581667543806054\n",
      "52 3.2937879717799734\n",
      "53 3.1292642865925817\n",
      "54 2.9644755563954894\n",
      "55 2.799358543012917\n",
      "56 2.6338975410020904\n",
      "57 2.4681144127010612\n",
      "58 2.302057504219474\n",
      "59 2.1357855187158874\n",
      "60 1.969344672720441\n",
      "61 1.8027481141302633\n",
      "62 1.6359733551969258\n",
      "63 1.4689804372992767\n",
      "64 1.3017341051725744\n",
      "65 1.134210877873211\n",
      "66 0.9663872491971651\n",
      "67 0.7982266766371467\n",
      "68 0.6296857665146126\n",
      "69 0.4607355047422752\n",
      "70 0.2913789970073121\n",
      "71 0.12165654146464294\n",
      "72 0.04836139836362963\n",
      "73 0.21858928723081045\n",
      "CPU times: user 2h 42min 54s, sys: 5min 7s, total: 2h 48min 1s\n",
      "Wall time: 43min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "a = .91 # скорость обучения\n",
    "\n",
    "er = [1e10]\n",
    "\n",
    "n_steps = 100\n",
    "\n",
    "for i in range(n_steps):\n",
    "    H,U,O = w2v_step(Wbin,Vi,Vo) # вычисляем состояния слоёв и выход\n",
    "    er.append(w2v_loss(U,Cbin)) # вычисляем ошибку\n",
    "    print(i+1, er[-1])\n",
    "    if er[-1]>er[-2]: \n",
    "        Vi, Vo = Vi_old, Vo_old\n",
    "        break\n",
    "        \n",
    "    gVi, gVo = w2v_grad(Cbin,Wbin,H,O,Vo) # вычисляем градиент ф-ции потери\n",
    "    gVi,gVo = w2v_weigth_norm(gVi,gVo) # нормируем значения градиента\n",
    "    \n",
    "    Vi_old, Vo_old =  Vi, Vo # сохраняем старые веса\n",
    "    \n",
    "    Vi,Vo = Vi-a*gVi, Vo-a*gVo # корректируем веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "er=er[1:]\n",
    "plt.plot(er)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## оцениваем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pairwise_distances(Vi) # матрица расстояний\n",
    "R = np.argsort(D) # номера слов в порядке увеличения расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'отправились': ['сын', 'фильмах', 'дерзил', 'отмазал'],\n",
       " 'упадет': ['пропусти', 'нежное', 'тормознуть', 'направления'],\n",
       " 'творение': ['шпаргалка', 'сигналит', 'убирала', 'пирамиду'],\n",
       " 'погас': ['свежевымытый', 'водится', 'несравненно', 'полюбопытствовал'],\n",
       " 'высунулась': ['прятавшегося', 'вставил', 'операцию', 'данным'],\n",
       " 'торжественность': ['выгодная', 'ресторанчики', 'обочине', 'пятую'],\n",
       " 'лимон': ['складу', 'напомнила', 'намучался', 'описывая'],\n",
       " 'снизил': ['ручкой', 'сыном', 'наркотики', 'зависимости'],\n",
       " 'стоила': ['навес', 'откликнулась', 'группе', 'итальянец'],\n",
       " 'бампером': ['мальчишке', 'невыразительное', 'карьера', 'родителей'],\n",
       " 'напоминал': ['орды', 'гаражной', 'установки', 'еврейская'],\n",
       " 'наезженные': ['рисует', 'режиссером', 'новеллы', 'подготовил'],\n",
       " 'выдохнул': ['стелился', 'помимо', 'сушиться', 'понимая'],\n",
       " 'ла-гвардейцев': ['стране', 'кофты', 'пророчествовал', 'тихой'],\n",
       " 'стойте': ['колесико', 'ламп', 'видимым', 'старичок'],\n",
       " 'бродвеем': ['царапающий', 'свежевымытый', 'повышенные', 'отговорку'],\n",
       " 'удержан': ['содрогнулся', 'выскажется', 'безумный', 'всячине'],\n",
       " 'играли': ['раззолоченных', 'спекуляции', 'свежевымытый', 'впредь'],\n",
       " 'кровью': ['отъехал', 'заработали', 'весел', 'занудливый'],\n",
       " 'выкуси': ['впускать', 'шмуэль', 'заявлением', 'колледже']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ = { v:k for k,v in vocab.items() } # нумеруем слов в словаре\n",
    "\n",
    "nn = rng.permutation(len(vocab))[:20] # выбираем случайно N слов\n",
    "\n",
    "# для выбранных слов печатаем близкие по w2v\n",
    "{ vocab_[i] : [ vocab_[j] for j in  R[i,1:5]  ] for i in nn }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
