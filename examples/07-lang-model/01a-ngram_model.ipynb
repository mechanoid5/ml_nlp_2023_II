{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9bfcd8",
   "metadata": {},
   "source": [
    "**Статистическая языковая модель**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>\n",
    "\n",
    "подбираем наиболее вероятное продолжение цепочки слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3347a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'символов:465490'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Теперь, когда уже все прошло, и я пишу хронику, мы уже знаем в чем дело; но тогда мы еще ничего не знали, и естественно, что нам представлялись странными разные вещи. По крайней мере мы со Степаном Трофимовичем в первое время заперлись и с испугом наблюдали издали. Я-то кой-куда еще выходил и по-прежнему приносил ему разные вести, без чего он и пробыть не мог.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import gzip\n",
    "\n",
    "file_name = '../data/dostoevsky-besy-p2.txt.gz'\n",
    "\n",
    "# загружаем текст ...\n",
    "with gzip.open(file_name,'rt') as f:  \n",
    "    text = f.read()[105:] # ...и выкидываем заголовок\n",
    "\n",
    "display(f'символов:{len(text)}')\n",
    "display(text[:364].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb6693b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nltk version: 3.8.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import __version__ as nltk_version\n",
    "display(f'nltk version: {nltk_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765735ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'предложений: 5556'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['-', 'О', ',', 'какое', 'извержение', 'чужих', 'слов', '!'],\n",
       " ['Вы', 'мой', 'идол', '!']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "from nltk.tokenize import sent_tokenize as nltk_sentence_split\n",
    "from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "\n",
    "text = [ \n",
    "    nltk_tokenize_word(s) # разбиваем предложения на слова\n",
    "    for s in nltk_sentence_split(text) # режем текст на отдельные предложения\n",
    "]\n",
    "\n",
    "display(f'предложений: {len(text)}')\n",
    "display( sample(text,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198033a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2331d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'всего слов тексте: 92240'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'размер словаря: 16631'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(',', 9513),\n",
       " ('.', 4067),\n",
       " ('-', 3005),\n",
       " ('и', 2870),\n",
       " ('не', 1688),\n",
       " ('в', 1648),\n",
       " ('что', 1262),\n",
       " ('?', 893),\n",
       " ('на', 842),\n",
       " ('с', 838)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "text_tokens = list(chain(*text)) # собираем все токены (слова) из текста\n",
    "vocab_size = len(set(text_tokens)) # размер словаря\n",
    "\n",
    "text_tokens_freq = Counter( text_tokens ) # оценка частоты использования слов\n",
    "\n",
    "display(f'всего слов тексте: {len(text_tokens)}')\n",
    "display(f'размер словаря: {vocab_size}') \n",
    "display( text_tokens_freq.most_common()[:10]) # наиболее частые токены"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468da34",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570e913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'количество n-gram: 54227'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('что-то', 'уж'),\n",
       " ('болтали', '!'),\n",
       " ('быть', 'посетит'),\n",
       " ('угрюмым', 'видом'),\n",
       " (',', 'что')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from nltk.util import bigrams\n",
    "from nltk.util import ngrams as nltk_ngrams\n",
    "\n",
    "\n",
    "# вынимаем все n-gram из текста\n",
    "ngram_len = 2 # работаем с биграммами\n",
    "text_ngrams = [ ngram for s in text for ngram in nltk_ngrams(s,ngram_len) ]\n",
    "display( f'количество n-gram: {len(set(text_ngrams))}')\n",
    "display( sample(text_ngrams,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7511d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('сама', 'поминутно'), 1),\n",
       " (('правительстве', '...'), 1),\n",
       " (('вы', 'поймете'), 1),\n",
       " (('Постойте', ','), 1),\n",
       " (('-', 'заметила'), 1),\n",
       " (('которых', 'еще'), 1),\n",
       " (('анекдота', ','), 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cчитаем частоту n-gram\n",
    "text_ngrams_freq = Counter(text_ngrams)\n",
    "display( sample( list(text_ngrams_freq.items()), 7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cb51f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'что'), 909),\n",
       " ((',', '-'), 699),\n",
       " ((',', 'и'), 495),\n",
       " ((',', 'а'), 431),\n",
       " ((',', 'но'), 351),\n",
       " ((',', 'как'), 235),\n",
       " ((',', 'я'), 209),\n",
       " ((',', 'не'), 206),\n",
       " ((',', 'в'), 189),\n",
       " (('-', 'Я'), 172)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( text_ngrams_freq.most_common()[:10] ) # наиболее частые n-ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3497d4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811451d6",
   "metadata": {},
   "source": [
    "Оценка вероятностей совместного использования слов со сглаживанием Лапласа\n",
    "\n",
    "\n",
    "$$\n",
    "P(w_n|w_{n-1}) = \\frac{ C(w_{n-1} w_{n}) +1 }{ C(w_{n-1}) + V }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc1eb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'Евангелие'), 7.649938800489595e-05),\n",
       " (('служение', 'честной'), 0.00012025012025012025),\n",
       " ((',', 'во'), 0.0006119951040391676),\n",
       " ((',', 'поддерживаемая'), 7.649938800489595e-05),\n",
       " (('тоже', 'больше'), 0.00011953858107704261),\n",
       " (('и', 'умер'), 0.00010255884313624942),\n",
       " (('мелочь', 'и'), 0.00012025012025012025),\n",
       " (('``', 'франтящею'), 0.00011821728336682824),\n",
       " (('огонь', 'пойдет'), 0.00012022843402464683),\n",
       " (('лишь', 'только'), 0.0001798668984951136),\n",
       " (('до', 'жадности'), 0.00011912561796414319),\n",
       " (('и', 'глухой'), 0.00015383826470437414)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_ngrams_prob = { # оценка совместного использования токенов\n",
    "    ngram : (text_ngrams_freq[ngram]+1) / ( text_tokens_freq[ ngram[0] ] + vocab_size )\n",
    "    for ngram in text_ngrams_freq \n",
    "}\n",
    "\n",
    "display( sample( list(text_ngrams_prob.items()), 12) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b505a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка вероятности новых ngram по статистике text_ngrams_prob\n",
    "def get_ngram_prob(ngram,text_ngrams_prob=text_ngrams_prob,text_tokens_freq=text_tokens_freq):\n",
    "    if ngram in text_ngrams_prob: return text_ngrams_prob[ngram]\n",
    "    token_0_freq = text_tokens_freq[ngram[0]] if ngram[0] in text_tokens_freq else 0.\n",
    "    return 1./(token_0_freq+len(text_tokens_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd71d3",
   "metadata": {},
   "source": [
    "выбираем дополнение предложения с наибольшей вероятностью цепочки слов\n",
    "\n",
    "$$\n",
    "P(w_1,\\ldots, w_n) = \\prod_{k=1}^{n} P(w_k|w_k-1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113e8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "from functools import reduce \n",
    "\n",
    "# оценка предложения\n",
    "def get_sentence_prob(\n",
    "        sentence,\n",
    "        text_ngrams_prob=text_ngrams_prob,\n",
    "        text_tokens_freq=text_tokens_freq,\n",
    "        ngram_len=ngram_len\n",
    "    ):\n",
    "    return reduce( mul, [ \n",
    "        get_ngram_prob(ngram,text_ngrams_prob=text_ngrams_prob,text_tokens_freq=text_tokens_freq)\n",
    "        for ngram in nltk_ngrams(sentence,ngram_len) \n",
    "    ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5aa732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка всех возможных продолжений предложения\n",
    "def get_next_token_prob(sentence,text_ngrams_prob=text_ngrams_prob,text_tokens_freq=text_tokens_freq):\n",
    "    \n",
    "    sentence_prob = get_sentence_prob( # оценка предложения\n",
    "            sentence,\n",
    "            text_ngrams_prob=text_ngrams_prob,\n",
    "            text_tokens_freq=text_tokens_freq\n",
    "        )\n",
    "    \n",
    "    token_next = { # оценки всех возможных продолжений\n",
    "        ngram[1] : \n",
    "            sentence_prob*\n",
    "              get_ngram_prob(ngram,text_ngrams_prob=text_ngrams_prob,text_tokens_freq=text_tokens_freq)\n",
    "        for ngram in text_ngrams_prob if ngram[0]==sentence[-1] \n",
    "    }\n",
    "    \n",
    "    return token_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c236e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_top_prob_token(tokens_prob,n=3):  # n наиболее вероятных продолжений\n",
    "    kf = lambda k: tokens_prob[k]\n",
    "    return OrderedDict([\n",
    "        (key,tokens_prob[key])\n",
    "        for key in sorted(tokens_prob, key=kf, reverse=True)[:n]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c1287",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67980f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">- То же самое и Петр Степаныч , как</font> -> <font style=\"color:red;\">бы вы и будто в</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">- Благослови вас бог , сударь , но при</font> -> <font style=\"color:red;\">этом чем людях всей первом</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Книгоношу заперли в каталашку , и только вечером ,</font> -> <font style=\"color:red;\">что - и а но</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Вся ваша фраза и даже выражение народ `` богоносец</font> -> <font style=\"color:red;\">''</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Официальная и даже секретная история `` нового поколения ''</font> -> <font style=\"color:red;\">, . и ? ;</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Воспитанники этого заведения , почти тотчас же по окончании</font> -> <font style=\"color:red;\">курса</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Пред ним в эту минуту лежало только что прочитанное</font> -> <font style=\"color:red;\">им</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Признаюсь , я всегда вас считала только за критика</font> -> <font style=\"color:red;\">;</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Такая поспешность такого надутого собою человека кольнула Степана Трофимовича</font> -> <font style=\"color:red;\">. , ) за больнее</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Капитан Лебядкин дней уже восемь не был пьян ;</font> -> <font style=\"color:red;\">но - я он она</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Об административных ошибках рассуждать тоже не мое дело ,</font> -> <font style=\"color:red;\">что - и а но</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">Но Алексей Егорович доложил , что вчера еще смазана</font> -> <font style=\"color:red;\">маслом</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">- Да , он приходил ; его цена тоже</font> -> <font style=\"color:red;\">, не для с в</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font style=\"color:black;\">- Это вряд ли в наше время возможно ,</font> -> <font style=\"color:red;\">что - и а но</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def cstr(s, color='black'):\n",
    "    return f'<font style=\"color:{color};\">{s}</font>'\n",
    "\n",
    "str_init_len = 9\n",
    "words_predict = 5\n",
    "\n",
    "# генерируем продолжения\n",
    "for sentence in sample(text,20): # выбираем рандомно N предложений\n",
    "    if len(sentence)<str_init_len+words_predict: continue # выкидываем очень короткие предложения\n",
    "    sentence_ = sentence[:str_init_len] # берём начало предложения\n",
    "    \n",
    "    # считаем верояности продолжений\n",
    "    next_token_prob = get_next_token_prob(sentence_) \n",
    "    \n",
    "    # выбираем наиболее вероятные\n",
    "    top_prob_token = get_top_prob_token(next_token_prob,n=words_predict)\n",
    "    result = ' '.join(top_prob_token.keys())\n",
    "      \n",
    "    display( HTML( cstr( ' '.join(sentence_)) + ' -> ' + cstr( result, color='red') ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60b4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
